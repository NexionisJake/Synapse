# Synapse AI Configuration
# Copy this file to .env and adjust values for your system

# Environment (development, production, testing)
FLASK_ENV=development

# AI Model Configuration
OLLAMA_MODEL=llama3:8b
OLLAMA_HOST=http://localhost:11434
OLLAMA_TIMEOUT=30

# Timeout Configuration (adjust based on your system performance)
# For low-end systems, increase these values:
RESPONSE_TIMEOUT=60
STREAMING_TIMEOUT=180

# For high-end systems, you can decrease these values:
# RESPONSE_TIMEOUT=30
# STREAMING_TIMEOUT=90

# Memory and Performance
MAX_CONVERSATION_LENGTH=100
CONVERSATION_CLEANUP_THRESHOLD=80
MAX_MEMORY_FILE_SIZE=10485760

# Security
MAX_MESSAGE_LENGTH=10000
MAX_PROMPT_LENGTH=5000

# Logging
LOG_LEVEL=INFO
LOG_FILE=synapse_errors.log

# Feature Flags
ENABLE_MEMORY_PROCESSING=True
ENABLE_SERENDIPITY_ENGINE=True
ENABLE_PROMPT_CUSTOMIZATION=True
ENABLE_PERFORMANCE_MONITORING=True

# System Performance Hints:
# Low-end systems (≤2 cores, ≤2GB RAM): STREAMING_TIMEOUT=300 (5 minutes)
# Medium systems (4 cores, 4-8GB RAM): STREAMING_TIMEOUT=180 (3 minutes) 
# High-end systems (≥8 cores, ≥8GB RAM): STREAMING_TIMEOUT=90 (1.5 minutes)